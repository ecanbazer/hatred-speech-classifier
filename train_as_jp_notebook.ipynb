{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7d02ftEA-hQg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import json\n",
        "from sklearn.utils import resample\n",
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5yCjbLmVJ3p",
        "outputId": "53d984c8-de2f-4ce1-c7b4-27e758b08c50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-A6iDGys4tkLxykSbXz41bbVRFBTATr1\n",
            "To: /content/train.csv\n",
            "\r  0% 0.00/3.10M [00:00<?, ?B/s]\r100% 3.10M/3.10M [00:00<00:00, 89.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download the data from google drive (will only work on Google Colab)\n",
        "!gdown --id 1-A6iDGys4tkLxykSbXz41bbVRFBTATr1 #training data\n",
        "#!gdown --id 1-M6Q93Dewd8EOf5Zwv_SbvWz4Vur1n-P #test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1sYhcokh-3_g"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"train.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaNqyudvV4kr"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yJPx798XAlkZ",
        "outputId": "c30066fc-7fd0-465b-f422-bf7daeba21cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e936eaa-35b8-44d6-b812-ab9783bf80b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e936eaa-35b8-44d6-b812-ab9783bf80b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e936eaa-35b8-44d6-b812-ab9783bf80b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e936eaa-35b8-44d6-b812-ab9783bf80b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation\n",
              "5   6      0  [2/2] huge fan fare and big talking before the...\n",
              "6   7      0   @user camping tomorrow @user @user @user @use...\n",
              "7   8      0  the next school year is the year for exams.ð...\n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiJVeViBF9Q9",
        "outputId": "4f48d8f1-03ed-4938-bfdf-9ac1bdcece61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31962 entries, 0 to 31961\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      31962 non-null  int64 \n",
            " 1   label   31962 non-null  int64 \n",
            " 2   tweet   31962 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 749.2+ KB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpECwMbNAVJq",
        "outputId": "1b4d866e-799a-4f98-aa73-1ec84a3a7f38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29720"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count not racist/sexist\n",
        "sum(train[\"label\"] == 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAWzDkQWF9PZ",
        "outputId": "116552f5-0ffe-4c7f-e611-069f000a2622"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2242"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count racist/sexist\n",
        "sum(train[\"label\"] == 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Z8E7RfrHuRF3",
        "outputId": "81bf48c9-5f8e-4a52-e59c-47c3ee19d3fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7f429ec78ed0>,\n",
              "  <matplotlib.axis.XTick at 0x7f429ec78e90>],\n",
              " <a list of 2 Text major ticklabel objects>)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot the data ratio\n",
        "plt.bar([0,1], train['label'].value_counts(), width=0.5, bottom=None, align='center', data=train)\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxH4eVK6zCu9",
        "outputId": "66358efd-933a-48fe-f80a-f66d163c23e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMRG6A4bI_WW"
      },
      "source": [
        "# Preprocessing step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSkd7yk_daRI"
      },
      "source": [
        "Our preprocessing function includes:\n",
        "- lemmatization\n",
        "- filtering by frequency > 1 (tokens that appear only one time in the whole dataset are removed from tweets)\n",
        "- de-accenting (for example, all 'â,à, ã' etc. becomes 'a'), since we found out that some words were written using non-english characters\n",
        "- only alphabetic strings \n",
        "- filtering by len > 2 (only words longer than 2 characters are kept)\n",
        "- stopwords removal except 'not', this was inspired by a paper on the same subject ([Waseem & Hovy 2016](https://aclanthology.org/N16-2013.pdf))\n",
        "- removing the sharp (#) from hashtags but keeping the hashtag text\n",
        "- de-emojiszing (turning emojis into words, eg. '💅'  to  'nail_care')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRACXSkb7DT3"
      },
      "source": [
        "We also noticed that some non-English words occur in the cleaned data. Ideally, we would also need to perform language identification and keep only English sentences, but it would complicate the preprocessing too much so we decided to keep it as it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5wzkGvoAVTR",
        "outputId": "c4973052-bdec-4752-d0dd-fe05ba1d7206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.3)\n"
          ]
        }
      ],
      "source": [
        "# Preprocessor\n",
        "!pip install tweet-preprocessor\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s00zqksQAVUM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import preprocessor as p\n",
        "from sklearn.model_selection import train_test_split\n",
        "import emoji\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from gensim.utils import deaccent\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXcgSu7hsDrG",
        "outputId": "027b5cfe-4d47-4e85-dd4c-1936f48ac21c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lyPsoBcxAVVo"
      },
      "outputs": [],
      "source": [
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.NUMBER) \n",
        "# set the pipeline of the tweet-preprocessor object to include only removing URL's, mentions ('@user'), and numbers\n",
        "\n",
        "def awesome_preprocessor(dataset, stopwords, lemmatizer, counter):\n",
        "  REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
        "  REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")  \n",
        "\n",
        "  cleaned = []\n",
        "  for tweet in dataset:\n",
        "    tweet = ' '.join([word for word in tweet.split() if word not in stopwords])\n",
        "    tweet = emoji.demojize(tweet.replace(':', ' '))  # de-emojizing adds unnecessary colons, like ':red_heart:'\n",
        "    tweet = p.clean(tweet)  # apply tweet-preprocessor\n",
        "    tweet = deaccent(tweet)  # de-accents with gensim's deaccent tool\n",
        "    tweet = REPLACE_NO_SPACE.sub(\"\", tweet.lower())\n",
        "    tweet = REPLACE_WITH_SPACE.sub(\" \", tweet)\n",
        "    tokens = nltk.word_tokenize(tweet)  \n",
        "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]  \n",
        "    filtered = []\n",
        "    for lemma in lemmas:\n",
        "      if counter[lemma] > 1 and lemma.isalpha() and len(lemma) > 2:\n",
        "        filtered.append(lemma)\n",
        "      elif lemma not in counter.keys():\n",
        "        filtered.append('<unk>')\n",
        "    tweet = \" \".join(filtered).replace('#', '')\n",
        "    cleaned.append(tweet)\n",
        "\n",
        "  return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DlgIRDD9aEfA"
      },
      "outputs": [],
      "source": [
        "# create a vocabulary of the dataset and count the occurences of each word (for frequency filtering)\n",
        "\n",
        "tokens = nltk.word_tokenize(\" \".join(list(train.tweet)))\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "vocab = [lemmatizer.lemmatize(token.lower()) for token in tokens]\n",
        "counter = Counter(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p5ztM80WAVXv"
      },
      "outputs": [],
      "source": [
        "# create a list of stopwords, without 'not' because it's important for our task\n",
        "stops = stopwords.words('english')\n",
        "stops.remove('not')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pqeya_nQwcm6"
      },
      "outputs": [],
      "source": [
        "# save counter to use it on new data too\n",
        "with open('counter.pickle', 'wb') as outputfile:\n",
        "    pickle.dump(counter, outputfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s2dZanl9AVZz"
      },
      "outputs": [],
      "source": [
        "train[\"cleaned\"] = awesome_preprocessor(train[\"tweet\"], stops, lemmatizer, counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SsLn23ZJAVcB",
        "outputId": "b42fc3b1-61fd-410a-a252-78c6d6d06490"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cac498ba-652e-4ee5-8730-5b03a2fcce73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "      <td>father selfish drag kid dysfunction run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "      <td>thanks lyft credit cant use cause offer wheelc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "      <td>bihday majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "      <td>model love take time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "      <td>factsguide society motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cac498ba-652e-4ee5-8730-5b03a2fcce73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cac498ba-652e-4ee5-8730-5b03a2fcce73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cac498ba-652e-4ee5-8730-5b03a2fcce73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  ...                                            cleaned\n",
              "0   1  ...            father selfish drag kid dysfunction run\n",
              "1   2  ...  thanks lyft credit cant use cause offer wheelc...\n",
              "2   3  ...                                     bihday majesty\n",
              "3   4  ...                               model love take time\n",
              "4   5  ...                      factsguide society motivation\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "Gws_ZSz8q0ks",
        "outputId": "83b8df04-cd05-462b-da55-ae5cbee495df"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_64ad1236-cf97-4dd2-ac1d-c5d99ff987f6\", \"preprocessed_train.csv\", 4782259)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3d3b11a7-8b8d-4595-8a58-373b4d5dc6de\", \"counter.pickle\", 1004503)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# download cleaned dataframe\n",
        "train.to_csv('preprocessed_train.csv')\n",
        "files.download('preprocessed_train.csv')\n",
        "\n",
        "# download built counter\n",
        "files.download('counter.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf3Iu6-AW36p"
      },
      "source": [
        "# Prepare for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLpAp8P-XDp"
      },
      "source": [
        "## Index mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAm8Ot-neKTq"
      },
      "source": [
        "Functions to map tokens to indexes. We also save the mapping to use it on new data later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l1xjYL2O-c2w"
      },
      "outputs": [],
      "source": [
        "def create_vocab(list_sents):\n",
        "    \"\"\"\n",
        "    Create an indexed vocab in dictionary form.\n",
        "    \n",
        "    list_sents: the list with the text data\"\"\"\n",
        "    vocab=[]\n",
        "    data_set = \" \".join(list_sents)\n",
        "    split_it = data_set.split()\n",
        "    counter = Counter(split_it)\n",
        "    #most_occur = counter.most_common(n)\n",
        "    for word, _ in dict(counter).items():\n",
        "        vocab.append(word)\n",
        "    vocab.append('<unk>')\n",
        "    vocab = sorted(vocab)\n",
        "    vocab = {w:i for i, w in enumerate(vocab)}\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fUQDOI81TxMI"
      },
      "outputs": [],
      "source": [
        "def index_and_pad(list_tweets, vocab, max_len):\n",
        "  \"\"\"\n",
        "  Return index-mapped and padded tweets.\n",
        "\n",
        "  list_tweets: the list of cleaned tweets\n",
        "  vocab: vocabulary that maps tokens to indexes\n",
        "  max_len: max length of tweets that we allow  (for padding)\n",
        "  \"\"\"\n",
        "  tweets_int = []\n",
        "  for tweet in list_tweets:\n",
        "    int_tweet = [vocab[w] if w in vocab else vocab['<unk>'] for w in tweet.split()]\n",
        "    tweets_int.append(int_tweet)\n",
        "  \n",
        "  features = np.zeros((len(tweets_int), max_len), dtype = int)\n",
        "  for i, tweet in enumerate(tweets_int):\n",
        "      tweet_len = len(tweet)\n",
        "      \n",
        "      if tweet_len <= max_len:\n",
        "          zeroes = list(np.zeros(max_len-tweet_len))\n",
        "          new = zeroes + tweet\n",
        "      elif tweet_len > max_len:\n",
        "          new = tweet[0:max_len]\n",
        "      \n",
        "      features[i, :] = list(new)\n",
        "  \n",
        "  return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x3Mjhawz5zQ"
      },
      "source": [
        "## Over Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuakTdQ3d4h9"
      },
      "source": [
        "Data is very imbalanced, so we will perform oversampling for the minority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "laY1YnG0BVmk"
      },
      "outputs": [],
      "source": [
        "def oversample(train_sample):\n",
        "  \"\"\"Oversample minoriity class because of the imbalance\"\"\"\n",
        "  # Separate majority and minority classes in training data for oversampling\n",
        "  train_majority = train_sample[train_sample['label'] == 0]\n",
        "  train_minority = train_sample[train_sample['label'] == 1]\n",
        "\n",
        "  print(\"majority class before oversample: \", train_majority.shape)\n",
        "  print(\"minority class before oversample: \", train_minority.shape)\n",
        "\n",
        "  # Upsample minority class\n",
        "  train_minority_oversampled = resample(train_minority, \n",
        "                                 replace=True,      # sample with replacement\n",
        "                                 n_samples= train_majority.shape[0],  # to match majority class\n",
        "                                 random_state=123)  # reproducible results\n",
        " \n",
        "  # Combine majority class with oversampled minority class\n",
        "  train_oversampled = pd.concat([train_majority, train_minority_oversampled])\n",
        "  # shuffling the data\n",
        "  train_oversampled = train_oversampled.sample(frac=1).reset_index(drop=True)\n",
        "  # Display new class counts\n",
        "  print(\"After oversampling\\n\", train_oversampled.label.value_counts(), sep = \"\")\n",
        "  return train_oversampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO_oAfan3GCg"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "tXOAWFya5mBu"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "  \"\"\"Dataset class for creating train, test, and val datasets (prepare the data). \"\"\"\n",
        "\n",
        "  def __init__(self, train, random_state=1, test_size=0.2):\n",
        "    \"\"\"Define train, validation, and test data.\"\"\"\n",
        "      \n",
        "    super().__init__()\n",
        "        \n",
        "    y = train.label.values\n",
        "    # use 80% for the training and 20% for the test\n",
        "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(train.cleaned.values, y, stratify=y, \n",
        "                                                                            random_state=random_state, test_size=test_size, shuffle=True)\n",
        "    # now take 10% of the training for validation\n",
        "    self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.x_train, self.y_train, stratify=self.y_train, \n",
        "                                                                          random_state=1, test_size=0.1, shuffle=True)\n",
        "    \n",
        "  def vectorizer(self):\n",
        "    \"\"\"Transform the text data into lists of integers.\"\"\"\n",
        "\n",
        "    # create mapping from tokens to indexes on train data\n",
        "    self.vocab = create_vocab(self.x_train)\n",
        "    # calculate max len tweet len in train data (in tokens)\n",
        "    self.max_len = len(max([tweet.split() for tweet in self.x_train], key=len))\n",
        "\n",
        "    # oversample data and create balanced train dataset\n",
        "    train_over = oversample(pd.DataFrame({\"tweet\": self.x_train, \"label\": self.y_train}))\n",
        "    self.y_train = train_over[\"label\"].to_numpy()\n",
        "    self.x_train = train_over[\"tweet\"]\n",
        "\n",
        "    # convert datasets to integers and pad them\n",
        "    self.x_train = index_and_pad(self.x_train, self.vocab, self.max_len)\n",
        "    self.x_val = index_and_pad(self.x_val, self.vocab, self.max_len)\n",
        "    self.x_test = index_and_pad(self.x_test, self.vocab, self.max_len)\n",
        "\n",
        "  def loaders(self, batch_size):\n",
        "    \"\"\"Create Tensor datasets, return data loaders.\"\"\"\n",
        "    #self.x_train=np.vstack(self.x_train).astype(np.int)\n",
        "\n",
        "    train_data = TensorDataset(torch.from_numpy(self.x_train), torch.from_numpy(self.y_train))\n",
        "    valid_data = TensorDataset(torch.from_numpy(self.x_val), torch.from_numpy(self.y_val))\n",
        "    test_data = TensorDataset(torch.from_numpy(self.x_test), torch.from_numpy(self.y_test))\n",
        "\n",
        "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "    valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader, self.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL6vTcXuW0Ud",
        "outputId": "e4f46b50-bef0-449f-a85a-6bb1aea3d26f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "majority class before oversample:  (21397, 2)\n",
            "minority class before oversample:  (1615, 2)\n",
            "After oversampling\n",
            "1    21397\n",
            "0    21397\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset(train)\n",
        "dataset.vectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N0NWosC3pqf9"
      },
      "outputs": [],
      "source": [
        "# save token-int mapping to use on new data\n",
        "with open(\"vocab.json\", \"w\") as outfile:\n",
        "    json.dump(dataset.vocab, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "vaedidG94BK4",
        "outputId": "c7682b53-e572-4130-ca60-8d25db716754"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_454317da-ca33-452c-a580-8b23202da318\", \"vocab.json\", 211467)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# download the mapping\n",
        "files.download('vocab.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mLjLRNKfZB9B"
      },
      "outputs": [],
      "source": [
        "batch_size = 200\n",
        "train_loader, valid_loader, test_loader, vocab = dataset.loaders(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXboaO6tW0ZM",
        "outputId": "ad89ea1e-9247-484a-b25c-a5d97cda8589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([200, 26])\n",
            "\n",
            "Sample label size:  torch.Size([200])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size())  # batch_size, seq_length\n",
        "#print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size())  # batch_size\n",
        "#print('Sample label: \\n', sample_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW4UBsOvaeL6",
        "outputId": "a716244b-17a1-48e5-b2c4-4742c99b1872"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "214"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcAEZOOvXy-O"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aejKGiztW0dm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LhkayoNjYAat"
      },
      "outputs": [],
      "source": [
        "class HatredSpeechLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob, train_on_gpu=False):\n",
        "        \"\"\"Initialize the model by setting up the layers.\"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.train_on_gpu = train_on_gpu\n",
        "        self.drop_prob = drop_prob\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"Perform a forward pass of our model on some input and hidden state.\"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initialize hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if self.train_on_gpu:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IxBYt0jZ92K",
        "outputId": "9197479c-4e39-4849-bdd7-1bcd2aca5e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.is_available())\n",
        "    train_on_gpu = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vwHQrTmYAcF",
        "outputId": "33819ab9-3ef8-4e4a-d0bf-921896f53c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HatredSpeechLSTM(\n",
            "  (embedding): Embedding(12237, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model with hyperparams\n",
        "vocab_size = len(dataset.vocab) + 1  # +1 is for zeros in padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "drop_prob = 0.5\n",
        "\n",
        "net = HatredSpeechLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob, train_on_gpu)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VSViLwLpYAdN"
      },
      "outputs": [],
      "source": [
        "if train_on_gpu:\n",
        "    net.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aEQBhX6YRfA"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gw428QDNW0hx"
      },
      "outputs": [],
      "source": [
        "# loss and optimization functions\n",
        "lr = 0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "# training params\n",
        "epochs = 15\n",
        "\n",
        "clip = 5  # gradient clipping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "KY_8uWodYkH5"
      },
      "outputs": [],
      "source": [
        "def train(net, epochs, train_loader, clip, batch_size, criterion, optimizer, train_on_gpu, valid_loader=None):\n",
        "  net.train()\n",
        "\n",
        "  loss_train_all_epochs = []\n",
        "  loss_val_all_epochs = []\n",
        "  fmeasure_val_all_epochs = []\n",
        "  best_fmeasure = 0  # \"optimal\" f-measure that will be used to perform validation\n",
        "\n",
        "  # training loop\n",
        "  for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # Initialize the training loss for the current epoch\n",
        "    loss_current_epoch = 0\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "      # Creating new variables for the hidden state, otherwise\n",
        "      # we'd backprop through the entire training history\n",
        "      h = tuple([each.data for each in h])\n",
        "\n",
        "      # zero accumulated gradients\n",
        "      net.zero_grad()\n",
        "\n",
        "      # get the output from the model\n",
        "      inputs = inputs.type(torch.LongTensor)\n",
        "      if train_on_gpu: inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "      if inputs.shape[0] != batch_size:  # for the last batch if it's smaller - don't do anything\n",
        "        continue\n",
        "      output, h = net(inputs, h)\n",
        "\n",
        "      # calculate the loss and perform backpropagation\n",
        "      loss = criterion(output, labels.float())\n",
        "      loss.backward()\n",
        "      # clip_grad_norm helps prevent the exploding gradient problem in LSTMs\n",
        "      nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "      optimizer.step()\n",
        "\n",
        "      # Add the batch loss to the current epoch loss\n",
        "      loss_current_epoch += loss.item()\n",
        "\n",
        "    # at the end of each epoch, record the loss over all batches and the accuracy on the validation set\n",
        "    loss_train_all_epochs.append(loss_current_epoch)\n",
        "\n",
        "    if valid_loader is None:  # if we don't have any validation data\n",
        "      val_loss_current_epoch, fmeasure_current_epoch = 0, 0\n",
        "    else:\n",
        "      val_loss_current_epoch, fmeasure_current_epoch = evaluate(net, valid_loader, batch_size, criterion, train_on_gpu)\n",
        "    loss_val_all_epochs.append(val_loss_current_epoch)\n",
        "    fmeasure_val_all_epochs.append(fmeasure_current_epoch)\n",
        "\n",
        "    # print the training and validation loss and validation fmeasure\n",
        "    print('Epoch [{}/{}],\\nOverall training loss: {:.4f};\\nMean training loss: {:.4f};\\nOverall validation loss: {:.4f};\\\n",
        "    \\nMean validation loss: {:.4f};\\nMean validation fmeasure: {:.4f}\\n'\n",
        "               .format(e+1, epochs, loss_current_epoch, loss_current_epoch / len(train_loader), val_loss_current_epoch,\n",
        "                       val_loss_current_epoch / (len(valid_loader) if valid_loader else 1), fmeasure_current_epoch))\n",
        "\n",
        "    # save the model to variable if the fmeasure is higher than the \"optimal\" value\n",
        "    if fmeasure_current_epoch >= best_fmeasure:\n",
        "      model_opt = net\n",
        "      best_fmeasure = fmeasure_current_epoch\n",
        "\n",
        "    # return to the training mode\n",
        "    net.train()\n",
        "\n",
        "  return model_opt, loss_train_all_epochs, loss_val_all_epochs, fmeasure_val_all_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xDEqvlY_9C74"
      },
      "outputs": [],
      "source": [
        "def evaluate(net, valid_loader, batch_size, criterion, train_on_gpu, _print=False):\n",
        "  val_h = net.init_hidden(batch_size)\n",
        "  val_loss_current_epoch = 0\n",
        "  net.eval()  # set to the eval mode\n",
        "  with torch.no_grad():\n",
        "    num_tp = 0\n",
        "    num_fp = 0\n",
        "    num_fn = 0\n",
        "\n",
        "    for inputs, labels in valid_loader:\n",
        "\n",
        "      val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "      inputs = inputs.type(torch.LongTensor)\n",
        "      if train_on_gpu: inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "      if inputs.shape[0] != batch_size:  # for the last batch that is smaller - don't do anything\n",
        "        continue\n",
        "      output, val_h = net(inputs, val_h)\n",
        "\n",
        "      val_loss = criterion(output.squeeze(), labels.float())\n",
        "      val_loss_current_epoch += val_loss.item()  # add the batch loss to the current epoch loss\n",
        "\n",
        "      # convert output probabilities to predicted class (0 or 1)\n",
        "      labels_pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "      tp, fn, fp = return_stats(labels, labels_pred)\n",
        "      if _print:\n",
        "        print('batch tp, fn, fp:', tp, fn, fp)\n",
        "        print('batch labels:', labels_pred)\n",
        "\n",
        "      num_tp += tp\n",
        "      num_fn += fn\n",
        "      num_fp += fp\n",
        "\n",
        "  f_measure = num_tp / (num_tp + 0.5 * (num_fp + num_fn))\n",
        "\n",
        "  if _print:\n",
        "    print('overall tp, fn, fp:', num_tp, num_fn, num_fp)\n",
        "\n",
        "  return val_loss_current_epoch, f_measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "MRZDUCJgQPAw"
      },
      "outputs": [],
      "source": [
        "def return_stats(first, second):\n",
        "  \"\"\"Get two boolean tensors, return number of TP, FN, and FP.\"\"\"\n",
        "  tp = torch.sum((first==second) * (first==1)).item()\n",
        "  fn = torch.sum((first!=second) * (first==1)).item()\n",
        "  fp = torch.sum((first!=second) * (first==0)).item()\n",
        "  return tp, fn, fp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXipVmPU9N8N",
        "outputId": "03e60369-4296-4c85-cd11-ee2019ed9fbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15],\n",
            "Overall training loss: 45.2688;\n",
            "Mean training loss: 0.2115;\n",
            "Overall validation loss: 2.5340;    \n",
            "Mean validation loss: 0.1949;\n",
            "Mean validation fmeasure: 0.6000\n",
            "\n",
            "Epoch [2/15],\n",
            "Overall training loss: 6.2458;\n",
            "Mean training loss: 0.0292;\n",
            "Overall validation loss: 3.1872;    \n",
            "Mean validation loss: 0.2452;\n",
            "Mean validation fmeasure: 0.6154\n",
            "\n",
            "Epoch [3/15],\n",
            "Overall training loss: 2.6124;\n",
            "Mean training loss: 0.0122;\n",
            "Overall validation loss: 3.8047;    \n",
            "Mean validation loss: 0.2927;\n",
            "Mean validation fmeasure: 0.6270\n",
            "\n",
            "Epoch [4/15],\n",
            "Overall training loss: 1.8919;\n",
            "Mean training loss: 0.0088;\n",
            "Overall validation loss: 4.2014;    \n",
            "Mean validation loss: 0.3232;\n",
            "Mean validation fmeasure: 0.6340\n",
            "\n",
            "Epoch [5/15],\n",
            "Overall training loss: 1.5683;\n",
            "Mean training loss: 0.0073;\n",
            "Overall validation loss: 3.8027;    \n",
            "Mean validation loss: 0.2925;\n",
            "Mean validation fmeasure: 0.6356\n",
            "\n",
            "Epoch [6/15],\n",
            "Overall training loss: 1.6824;\n",
            "Mean training loss: 0.0079;\n",
            "Overall validation loss: 3.3361;    \n",
            "Mean validation loss: 0.2566;\n",
            "Mean validation fmeasure: 0.6520\n",
            "\n",
            "Epoch [7/15],\n",
            "Overall training loss: 1.0561;\n",
            "Mean training loss: 0.0049;\n",
            "Overall validation loss: 4.0834;    \n",
            "Mean validation loss: 0.3141;\n",
            "Mean validation fmeasure: 0.6536\n",
            "\n",
            "Epoch [8/15],\n",
            "Overall training loss: 0.6918;\n",
            "Mean training loss: 0.0032;\n",
            "Overall validation loss: 4.5544;    \n",
            "Mean validation loss: 0.3503;\n",
            "Mean validation fmeasure: 0.6275\n",
            "\n",
            "Epoch [9/15],\n",
            "Overall training loss: 0.6775;\n",
            "Mean training loss: 0.0032;\n",
            "Overall validation loss: 4.5107;    \n",
            "Mean validation loss: 0.3470;\n",
            "Mean validation fmeasure: 0.6169\n",
            "\n",
            "Epoch [10/15],\n",
            "Overall training loss: 0.5988;\n",
            "Mean training loss: 0.0028;\n",
            "Overall validation loss: 4.9576;    \n",
            "Mean validation loss: 0.3814;\n",
            "Mean validation fmeasure: 0.6387\n",
            "\n",
            "Epoch [11/15],\n",
            "Overall training loss: 1.3287;\n",
            "Mean training loss: 0.0062;\n",
            "Overall validation loss: 3.8064;    \n",
            "Mean validation loss: 0.2928;\n",
            "Mean validation fmeasure: 0.6431\n",
            "\n",
            "Epoch [12/15],\n",
            "Overall training loss: 1.5421;\n",
            "Mean training loss: 0.0072;\n",
            "Overall validation loss: 4.3564;    \n",
            "Mean validation loss: 0.3351;\n",
            "Mean validation fmeasure: 0.6020\n",
            "\n",
            "Epoch [13/15],\n",
            "Overall training loss: 1.4750;\n",
            "Mean training loss: 0.0069;\n",
            "Overall validation loss: 3.6526;    \n",
            "Mean validation loss: 0.2810;\n",
            "Mean validation fmeasure: 0.6667\n",
            "\n",
            "Epoch [14/15],\n",
            "Overall training loss: 0.7996;\n",
            "Mean training loss: 0.0037;\n",
            "Overall validation loss: 3.9501;    \n",
            "Mean validation loss: 0.3039;\n",
            "Mean validation fmeasure: 0.6734\n",
            "\n",
            "Epoch [15/15],\n",
            "Overall training loss: 0.6274;\n",
            "Mean training loss: 0.0029;\n",
            "Overall validation loss: 4.5889;    \n",
            "Mean validation loss: 0.3530;\n",
            "Mean validation fmeasure: 0.6645\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model, loss_train_all_epochs, loss_val_all_epochs, fmeasure_val_all_epochs = train(net, epochs, train_loader, clip, batch_size,\n",
        "                                                                                criterion, optimizer, train_on_gpu, valid_loader)\n",
        "\n",
        "# returned 'model' is the best among epochs according to fmeasure on validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KaSNgkh3DD9A",
        "outputId": "0f5c2c88-f4cd-4a91-b1c8-9d1480e5c876"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the training and validation losses and (validation) f-measure over epochs\n",
        "plt.figure()\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(loss_train_all_epochs)\n",
        "plt.title('Training loss')\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(loss_val_all_epochs)\n",
        "plt.title('Validation loss')\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(fmeasure_val_all_epochs)\n",
        "plt.title('Validation fmeasure')\n",
        "plt.show()\n",
        "plt.savefig('output.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xZWEJeGFXrY"
      },
      "source": [
        "The results above are a bit surprising. The training loss is, as expected, going down and validation f-measure is going up (though not steadily). However, validation loss is also going up, which is not supposed to be the case. We couldn't think of an explanation of such a behaviour but since f-measure is increasing, we decided to keep it as it is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "cINLxtWR1f9s",
        "outputId": "f26299f4-a281-4fe0-b0b6-50bd1051ca5c"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_39d14ead-fef2-41b9-b7e4-2ff0bb6c3a92\", \"output.png\", 1273)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('output.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "Aw6BFqpVC_N2",
        "outputId": "5bcfdd5c-b324-4d42-fb7d-2189d08ca772"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5de7eae7-00cd-4a7a-bd2f-df542b652767\", \"checkpoint.pth\", 24382879)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# save the model to a checkpoint\n",
        "torch.save(model.state_dict(), 'checkpoint.pth')\n",
        "\n",
        "# download checkpoint file\n",
        "files.download('checkpoint.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gum-kUvkxmzS"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GMbX5zm-oBlq"
      },
      "outputs": [],
      "source": [
        "loss_last_epoch, f_measure = evaluate(net, test_loader, batch_size, criterion, train_on_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QGzFUhobWUJ",
        "outputId": "30f8335f-21d4-439f-8919-17842ceffbe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10.822600156068802 0.6825595984943539\n"
          ]
        }
      ],
      "source": [
        "print(loss_last_epoch, f_measure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5aujsPX3V07n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "project hatred speech detection .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
